\chapter{Graph Vertex Similarity}
\label{ch:bg-graph-similarity}

The problem of computing the similarity between nodes in a graph has been
well-studied under the context of link prediction~\cite{link-prediction-survey},
anomaly detection~\cite{graphsim-anomaly},
recommendation~\cite{graphsim-recommendation}, and information retrieval
~\cite{graphsim-retrieval}. Therefore a
number of algorithms have been proposed to tackle the issue.
In this chapter we provide an introduction to the problem and
highlight some of the established approaches as well as recent
research focused on scalability. We divide the approaches into local
and global based on their ability to determine the similarity of nodes
based on local information or by looking into the entire graph, as done in
~\cite{link-prediction-survey}.
In this chapter we focus on
measures that use the structure of the graph to determine the similarity,
however for specific applications there exist similarity measures
based on content or curated databases such as utilizing the graph
structure of the Wordnet databaset \cite{wordnet-similarity, wordnet-relatedness, wordsim}.

As the problem is closely related to link prediction, we point the interested reader to
the survey by \citet{link-prediction-survey} or the more
recent \cite{link-prediction-survey-2017} on the subject,
that include vertex similarity algorithms.

\subsection*{Preliminaries}


We denote the graph $G(V, E)$ where $V$ is the set of vertices and $E$ the set
of edges. When discussing computational cost, we denote the average degree of the graph as $d$.
To ease notation we assume undirected graphs, however most of the methods
mentioned here can apply to directed graphs as well.
For a node $v \in V$, $N(v)$ denotes the set of nodes in $v's$ \emph{neighborhood},
that is, all the nodes that are reachable from $v$ within a single hop.
We denote the adjacency matrix of the graph by $\mathbf{A}$.


\section{Local Similarity Measures}

Local similarity measures generally determine the similarity between
nodes by examining structural properties between nodes that
are 2 hops apart in the graph. While this limits their ability to model long-range
similarities, they have been shown to have accurate results, and are computationally
efficient~\cite{link-prediction-survey}. In the sequel we present some of the most popular local similarity measures.


\emph{Common Neighbors.} This method makes the assumption that nodes that
share many common neighbors will be similar themselves. The complexity of
the method is $O(|V|d^2)$. For two nodes $u, v$
it is simply denoted as:

\begin{equation}
	S_{CN} = |N(u) \cap N(v)|
\end{equation}


\emph{Jaccard Coefficient.} The Jaccard coefficient~\cite{Jaccard1912} measures the similarity between
sets, defined as the size of the intersection of the two sets, divided by the size of their
union. Its definition is the following, and has the same complexity as Common Neighbors:

\begin{equation}
	S_{Jac} = \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}
\end{equation}

\emph{S{\o}rensen-Dice coefficient.} The S{\o}rensen-Dice measure \cite{Dice45,Sorensen48} is
analogous to the Jaccard index through a monotonic transform and is defined as:

\begin{equation}
	S_{SD} = \frac{2|N(u) \cap N(v)|}{d_u + d_v}
\end{equation}

\noindent
where $d_u, d_v$ denote the degrees of nodes $u$ and $v$ respectively.

\emph{Adamic/Adar index}. This measure relies on shared neighbors to determine
the similarity of nodes, and was originally proposed for the task of link
prediction~\cite{adamic-adar}. It is defined as:

\begin{equation}
	S_{AA} = \sum_{y \in N(u) \cap N(v)}{\frac{1}{\log{|N(y)|}}}
\end{equation}

\emph{Resource Allocation}. This measure was also developed for the
link prediction task~\cite{resource-allocation-sim}, and has a definition
similar to the Adamic/Adar measure:

\begin{equation}
S_{RA} = \sum_{y \in N(u) \cap N(v)}{\frac{1}{|N(y)|}}
\end{equation}

\section{Global Similarity Measures}

Global methods use information from the complete graph to determine the
similarity between nodes that can be more than two hops apart. These methods
are commonly iterative and have a much higher computational cost than local
measures, as they calculate all-to-all rather than local similarities.
The general approach is to calculate the similarity in a recursive manner:
Two nodes are considered similar if their neighbors are also similar.
The algorithms listed below all use some variation of this principle.

\emph{Katz index.} The Katz index \cite{vertex-similarity-survey} is based out the Katz centrality
measure~\cite{katz-index} that determines the centrality of a node
based on the number of paths between two nodes. The measure can be
defined as:

\begin{equation}
	S_{Katz} = [I - \beta \mathbf{A}]^{-1}
\end{equation}

\noindent
where $\beta$ is a parameter of the algorithm.

\emph{SimRank}. In SimRank~\cite{simrank} vertices are considered
to be similar if they are related to similar objects. It is defined
in a recursive manner as:

\begin{equation}
	S_{SR}(u, v)= C \cdot \frac{\sum_{y \in N(u)} \sum_{y^{\prime} \in N(v)} S_{SR}(y, y^{\prime})}{d_{x} \cdot d_{y}}
\end{equation}

\noindent
where $C$ is a decay factor. Compared to the Katz measure described above,
SimRank only includes paths of even length, which can affect the similarity
calculation~\cite{vertex-similarity-survey}, and can result to invalid results
for bipartite graphs. SimRank is also very computationally intensive with cubic
runtime cost with respect to the number of nodes. Optimized versions like
\cite{simrankOpt} have been proposed to alleviate this drawback.
The measure proposed in \citet{blondel-similarity} is also closely related to SimRank
and has the same drawbacks.

\emph{Average Commute Time.} This metric makes use of random walks to determine
the average number of steps required to reach node $v$ from node $u$. The assumption
this method makes is that two nodes are more similar if they have a smaller average
commute distance, and is defined in terms of elements $l$ of the pseudoinverse of the
graph Laplacian, $L$ as defined in \cite{link-prediction-survey}\todo{Define Laplacian?}.

\begin{equation}
	S_{ACT}(u, v)=\frac{1}{l_{u, u}^{+}+l_{v, v}^{+}-2 l_{uv}^{+}}
\end{equation}


\section{Applications}

As a general graph problem the applications of node similarity are as varied
as the problems that we can model using a graph representation. In this
section we will provide a few example application that exemplify the importance
of the problem.

One of the areas where node similarity has been most successful is link
prediction. In the link prediction task, we try to predict missing
edges in a graph, which might represent real connections that are encoded
in the graph, or connections which are yet to happen in the real world.
In the taxonomy of link prediction methods proposed by
\citet{link-prediction-survey-2017}, node similarity is one of the
four major categories of algorithms, alon with probabilistic and
statistical methods, algorithmic methods and pre-processing methods.
The usual way that node similarity methods are used for link prediction
is that node pairs are ranked by the similarity score given by the
algorithm and the top-ranked pairs of nodes that are currently not connected
in the graph are considered the most likely to form a connection.
In the paper describing the Resource Allocation measure, \citet{resource-allocation-sim}
example consider the probability of a true missing link
being given a higher score than a randomly chosen missing link
to evaluate the accuracy of their method.


Node similarity has also been explored in the context of recommendation.
The Average Commute Distance~\cite{average-commute-distance} metric mentioned above, uses the distance
required by a random walker to move between two nodes as an indication
of the similarity between nodes. The authors make us of this score
to provide recommendations, either using a direct approach, where
the similarity between users and items is calculated on the same
graph, or indirectly, by first measuring the similarity between
users in a graph, and then determining the preference of said
user for an item given the preferences of their top-k neighbbors
for that particular item.
\citet{trust-similarity} use vertex similarity to recommend trustworthy
nodes to a query node that belongs in the same trust network.
The similarity is calculated this time between
nodes in two graphs, the structure graph and the trust network,
using again structural information between the graphs.

Vertex similarity methods have also been used in natural
language processing, to determine the similarity between
words and documents. \citet{semantic-similarity} make use
of a diffusion process on a lexicon graph where nodes
are terms in the text and edges represent co-occurrence.
This allows them to discover semantic relationships between
nodes that are not directly connected in the graph, but
can however be semantically related. \citet{semantic-sim-random-walk}
on the other hand calculate similarities using random walks between words
in the Wordnet~\cite{wordnet} graph to estimate their semantic
similarity. A similar approach is taken in \cite{wordnet-graph-sim},
where the authors use the distance between the common ancestors
of words in WordNet. More recently, \citet{word-sim-concepts} uses
a combination of the WordNet graph, embedding methods like GloVe~\cite{glove}
and a concept dictionary to determine the semantic similarity between
words.