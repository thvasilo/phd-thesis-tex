%!TEX root = ../main.tex

\begin{abstract}
Machine learning algorithms are now being deployed in practically all
areas of our lives. Part of this success can be
attributed to the ability to learn complex representations from
massive datasets.
However, computational speed increases have not kept up with
the increase in the sizes of data we want to learn from,
leading naturally to algorithms that need to be resource-efficient and parallel.
As the proliferation of machine learning continues, the
ability for algorithms to adapt to a changing environment and deal with uncertainty becomes
increasingly important.

In this thesis we develop scalable machine learning algorithms, with a focus on
efficient, online, and distributed computation. We make use of \emph{approximations}
to dramatically reduce the computational cost of exact algorithms, develop
\emph{online learning} algorithms to deal with a constantly changing environment
under a tight computational budget, and develop \emph{parallel and distributed} algorithms
to ensure that our algorithms can scale to massive datasets.

We first propose a scalable algorithm for vertex similarity calculation and concept
discovery. We demonstrate
its applicability to multiple domains and demonstrate its scalability by training on
one of the largest text corpora available in the order of minutes.
Then, motivated by a real-world use case of predicting the session length in media streaming, we propose improvements to several aspects of learning
with decision trees. We propose two algorithms to estimate the uncertainty in the predictions
of online random forests. We show that our approach can achieve better accuracy than the
state of the art while being an order of magnitude faster to run.
We then propose a parallel and distributed online tree boosting algorithm
that maintains the correctness guarantees of serial algorithms while providing an order of
magnitude speedups on average. Finally, we propose an algorithm that allows for gradient boosted trees training to be
distributed across both the data point and feature dimensions. We show that we can
achieve communication savings of several orders of magnitude for sparse datasets,
compared to existing approaches that can only distribute the computation across the
data point dimension and use dense communication.
\end{abstract}
